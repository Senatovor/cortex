import uuid
import pandas as pd
from loguru import logger
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

from ..config import config
from .agents import agent_generate_sql, agent_deep_talking, agent_optimized_sql, agent_intent_classifier
from .qdrant import vector_manager
from .rag_scheme import AgentState


def user_input(state: AgentState):
    """–ü—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç –≤–≤–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–∏—à–µ–ª –∏–∑–≤–Ω–µ"""
    return {
        "messages": [HumanMessage(content=state.current_user_input)]
    }


def check_to_end(state: AgentState):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ –∏—Å—Ç–æ—Ä–∏–∏"""
    dialog_messages = [m for m in state.messages if isinstance(m, (HumanMessage, AIMessage))]

    if len(dialog_messages) >= 45:
        print('–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω')
        return 'end'
    print(f'–°–æ–æ–±—â–µ–Ω–∏–π: {len(dialog_messages)}')
    return 'continue'


def classify_intent_node(state: AgentState):
    """–£–∑–µ–ª –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞–º–µ—Ä–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    user_input = state.current_user_input

    try:
        # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –Ω–∞–º–µ—Ä–µ–Ω–∏–µ
        result = agent_intent_classifier.invoke(
            input={"messages": [HumanMessage(content=user_input)]},
            config={"configurable": {"thread_id": 'intent_session'}},
        )
        intent = result['structured_response']

        print(f"üîç –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ: {intent.intent_type}")
        print(f"üìä –¢—Ä–µ–±—É–µ—Ç—Å—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞: {intent.requires_analytics}")
        print(f"üìà –û—Ü–µ–Ω–∫–∞ –æ–±—ä–µ–º–∞: {intent.data_volume_estimate}")

        return {
            "query_intent": intent.dict(),
            "message_type": intent.intent_type
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
        return {
            "query_intent": {
                "intent_type": "unknown",
                "requires_analytics": False,
                "data_volume_estimate": "unknown"
            }
        }


def execute_sql_query(sql_query: str):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç SQL –∑–∞–ø—Ä–æ—Å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç"""
    try:
        engine = create_engine('postgresql://postgres:1111@localhost:5433/fastapp')

        with engine.connect() as conn:
            result = conn.execute(text(sql_query))
            columns = result.keys()
            rows = result.fetchall()
            data = [dict(zip(columns, row)) for row in rows]
            df = pd.DataFrame(data)

        return {
            "success": True,
            "data": data,
            "dataframe": df,
            "row_count": len(data),
            "columns": list(columns)
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


def sql_generate_node(state: AgentState):
    """–£–∑–µ–ª –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SQL –∑–∞–ø—Ä–æ—Å–∞"""
    user_input = state.current_user_input
    intent = state.query_intent or {}

    try:
        structure_store = vector_manager.get_vector_store('structure')
        sql_info_scheme = structure_store.similarity_search(user_input)
        print(f"üìö –ù–∞–π–¥–µ–Ω–æ {len(sql_info_scheme)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü")

        schema_info = ""
        for doc in sql_info_scheme:
            table_name = doc.metadata.get('table_name', 'unknown')
            schema_info += f"–¢–∞–±–ª–∏—Ü–∞: {table_name}\n"
            schema_info += f"–û–ø–∏—Å–∞–Ω–∏–µ: {doc.page_content}\n\n"

        # –í—ã–±–∏—Ä–∞–µ–º –∞–≥–µ–Ω—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–∞–º–µ—Ä–µ–Ω–∏—è –∏ –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö
        if intent.get('requires_analytics') and intent.get('data_volume_estimate') in ['large', 'medium']:
            print("üîÑ –ò—Å–ø–æ–ª—å–∑—É—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π SQL –∞–≥–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏")
            result = agent_optimized_sql.invoke(
                input={"messages": [HumanMessage(content=user_input)]},
                config={"configurable": {"thread_id": 'optimized_sql_session'}},
                context={
                    "sql_structure": schema_info,
                    "user_intent": intent
                }
            )
            sql_query = result['structured_response'].sql_query
            print(f"üìù –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π SQL: {sql_query}")
        else:
            print("üîÑ –ò—Å–ø–æ–ª—å–∑—É—é —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π SQL –∞–≥–µ–Ω—Ç")
            result = agent_generate_sql.invoke(
                input={"messages": [HumanMessage(content=user_input)]},
                config={"configurable": {"thread_id": 'sql_generate_session'}},
                context={"sql_structure": schema_info}
            )
            sql_query = result['structured_response'].sql_query
            print(f"üìù –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π SQL: {sql_query}")

        # –í—ã–ø–æ–ª–Ω—è–µ–º SQL –∑–∞–ø—Ä–æ—Å
        execution_result = execute_sql_query(sql_query)
        print(execution_result)

        if not execution_result["success"]:
            error_msg = f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è SQL: {execution_result['error']}"
            return {
                "messages": [AIMessage(content=error_msg)],
                "sql_query": sql_query
            }

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö
        row_count = execution_result["row_count"]
        if row_count < 100:
            data_volume = "small"
        elif row_count < 1000:
            data_volume = "medium"
        else:
            data_volume = "large"

        print(f"üìä –ü–æ–ª—É—á–µ–Ω–æ —Å—Ç—Ä–æ–∫: {row_count} (–æ–±—ä–µ–º: {data_volume})")

        return {
            "messages": [AIMessage(content=f'–Ø –Ω–∞—à–µ–ª –¥–∞–Ω–Ω—ã–µ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é...')],
            "sql_query": sql_query,
            "data_summary": execution_result['data'],
            "data_volume": data_volume
        }

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SQL: {e}")
        error_message = AIMessage(content="–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞.")
        return {
            "messages": [error_message]
        }


def analytics_data_summary_node(state: AgentState):
    """–£–∑–µ–ª –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    user_input = state.current_user_input
    data_summary = state.data_summary
    data_volume = state.data_volume
    intent = state.query_intent or {}

    print('ü§î –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é, —á—Ç–æ –¥–µ–ª–∞—Ç—å —Å –¥–∞–Ω–Ω—ã–º–∏...')

    try:
        # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ –∏ –∏—Ö –Ω–µ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ
        if not intent.get('requires_analytics', False):
            print("üìã –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–ø—Ä–æ—Å–∏–ª —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ, –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—ã–≤–æ–¥–∞
            if data_volume == "large":
                # –î–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 20 —Å—Ç—Ä–æ–∫ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                preview = data_summary[:20]
                total = len(data_summary)
                response = f"–ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {total}\n\n"
                response += "–ü–µ—Ä–≤—ã–µ 20 –∑–∞–ø–∏—Å–µ–π:\n"
                for i, row in enumerate(preview, 1):
                    response += f"{i}. {row}\n"
                response += f"\n... –∏ –µ—â–µ {total - 20} –∑–∞–ø–∏—Å–µ–π"
            else:
                # –î–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å—ë
                response = "–ù–∞–π–¥–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\n"
                for i, row in enumerate(data_summary, 1):
                    response += f"{i}. {row}\n"

            return {
                "messages": [AIMessage(content=response)],
            }

        # –ï—Å–ª–∏ –Ω—É–∂–Ω–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞
        print("üìä –¢—Ä–µ–±—É–µ—Ç—Å—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞")

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
        if data_volume == "large":
            # –î–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –¥–µ–ª–∞–µ–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é –∞–≥—Ä–µ–≥–∞—Ü–∏—é
            df = pd.DataFrame(data_summary)
            summary_stats = df.describe().to_string() if not df.empty else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
            preview = data_summary[:20]

            analytics_data = f"""
            –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:
            {summary_stats}

            –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(data_summary)}

            –ü—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö (–ø–µ—Ä–≤—ã–µ 20):
            {preview}
            """
        else:
            # –î–ª—è –º–∞–ª—ã—Ö/—Å—Ä–µ–¥–Ω–∏—Ö –æ–±—ä–µ–º–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
            analytics_data = str(data_summary)

        print(analytics_data)
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–≥–µ–Ω—Ç
        result = agent_deep_talking.invoke(
            input={"messages": [
                SystemMessage(content=f"""
                –ü—Ä–æ–≤–µ–¥–∏ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –≠–¢–û –†–ï–ê–õ–¨–ù–´–ï –î–ê–ù–ù–´–ï

                –î–∞–Ω–Ω—ã–µ: {analytics_data}
                """)
            ]},
            config={"configurable": {"thread_id": 'analytic_session'}},
            context={
                "sql_result": analytics_data,
                "user_question": user_input,
                "intent_type": "analytics"
            }
        )

        return {
            "messages": [AIMessage(content=result['messages'][-1].content)],
        }

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        error_message = AIMessage(content="–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–∞–Ω–Ω—ã—Ö.")
        return {
            "messages": [error_message]
        }